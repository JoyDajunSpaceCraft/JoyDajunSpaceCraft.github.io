---
layout: post
title: ' ParlAI Chatbot '
subtitle: ' ParlAI Chatbot '
date: 2020--12-25
author: 'Joy'
header-img: 'img/ParlAI.jpg'
tags:
  - Python
  - Chatbot
  - paper-reading
---
# ParlAI: A Dialog Research Software Platform Alexander 阅读
## abstract 
一个用Python实现的对话研究的开源软件平台，可在http://parl.ai。其目标是提供一个统一的框架，用于共享、培训和测试对话模型；集成Amazon Mechani-cal Turk进行数据收集、人类评估和在线/强化学习；以及一个机器学习模型库，用于与其他模型进行比较，并改进现有架构。超过20个任务在第一次重新租赁支持，包括流行的数据集，SQuAD, bAbI tasks，MCTest，维基，QACNN，QADailyMail，CBT，bAbI Di-alog，Ubuntu，OpenSubtitles和VQA。集成了几种模型，包括记忆网络、seq2seq和注意LSTMs等神经模型。


## 介绍

语言的目的是为了达到交流的目的，这通常涉及到两个或多个交流者之间的对话（Crystal，2004）。因此，试图解决对话是NLP社区研究人员的基本目标。从机器学习的角度来看，构建一个能够对话的学习代理也是很有趣的，原因很多，主要是解决方案涉及到实现领域的大多数子目标，而且在许多情况下，这些子任务直接影响任务。一方面，对话可以看作是一种罪恶-

gle任务（学习如何交谈）和另一方面，作为数千个相关的任务，需要不同的技能，所有的输入和输出格式相同。预定餐厅、聊天的任务，关于体育或新闻，或回答事实或感性的问题都属于Dialog。因此，执行任务转移的方法对最终目标很有用。记忆、逻辑和常识推理、计划、交互学习、学习组合性和其他人工智能子目标在对话中也有明确的作用。然而，为了追求这些研究目标，软-

软件工具应该统一不同的对话子任务和可以从中学习的代理。处理单个数据集可能会导致孤立


## Goal 
开发dia-log模型的统一框架。ParlAI的目标是将提供给机器学习代理的对话数据集输入格式统一为单一格式，并尽可能使评估框架和指标标准化。搜索者可以将他们的新任务和他们的代理培训代码提交到存储库，以便与其他人共享，以帮助再现性，并更好地支持后续研究。

涉及许多不同技能的一般对话。ParlAI包含真实和模拟语言数据集的无缝组合，并通过使多任务模型与单任务模型一样易于构建，鼓励多任务模型的开发和评估。这将减少模型设计对特定数据集的过度拟合，并鼓励执行任务转移的模型，这是通用对话代理的一个重要先决条件。

真正与人对话。ParlAI通过Amazon Mechanical Turk可以收集、培训和评估与hu-mans的实时对话，这使得Turkers与对话代理之间的连接更加容易，见图2。这也使得比较不同研究小组Turker实验成为可能，这在历史上是很困难的。一个通用的对话模型。我们的目标是激励构建新的任务和代理，使领域朝着工作的方向发展。因此，进入知识库的每个新任务都应该朝着这个共同目标努力，而不是仅仅被看作是一项独立的研究。

## 基本属性
ParlAI由许多任务和代理组成，可以用来解决这些问题。ParlAI中的所有任务都有一个单一格式（API），这使得将任何代理应用于任何任务或同时执行多个任务变得简单。这些任务包括固定的监督/模拟学习数据集（即会话日志）和交互式（在线或强化学习）任务，以及真实语言和模拟任务，这些任务都可以无缝地进行培训。ParlAI还支持其他媒体，例如图像以及视觉问题解答文本（Antol等人，2015年）或基于视觉的对话（Das等人，2017年）。ParlAI会在任务和数据集首次使用时自动下载它们。可以在环境（任务）中嵌入一个或多个机械突厥器来收集数据、训练或评估学习代理。示例包含在

与PyTorch 和 Lua Torch一起训练。ParlAI使用ZeroMQ与Python以外的语言（如Lua Torch）进行对话。代码中支持模型的批训练和hog-wild训练。图3给出了用于训练主代理的示例。

## 几个概念的解析

World,agent teacher
World-环境。这可以从非常简单（例如只有两个agent进行转换）到更复杂（例如交互环境中的多个代理）。

•agent——能够在世界范围内行动（尤其是说话）的agent。agent可以是学习者（即机器学习系统），也可以是硬编码的机器人，例如设计用来与学习者或人类（如Turker）互动的机器人。

•teacher一种与学习者对话以进行教学的代理，例如执行图1中的任务之一。

在定义了一个世界和其中的代理人之后

主循环可以运行用于训练、测试或显示，调用函数世界谈判（）跑世界的一步。图3给出了显示数据的示例代码，运行该代码的输出如图4所示

## Actions and Observations
所有的agent（包括teacher）都以一种单一的通用格式（观察/动作对象（python dict）进行交互，见图5。它用于在代理之间传递文本、标签和奖励。同一对象类型用于说话（演戏）和倾听（观察），但字段中的值不同。因此，对象从代理.act传入并传递给（）探员。观察（），见图3。信息的字段如下：
+ text: a speech act. 
+ id: the speaker’s identity. 
+ reward: a real-valued reward assigned to the receiver of the message.
+ episode done: indicating the end of a dialog.
+ label: a set of answers the speaker is expect- ing to receive in reply, e.g. for QA datasets the right answers to a question.
+  label candidates: a set of possible ways to respond supplied by a teacher, e.g. for multi- ple choice datasets or ranking tasks.
+ text candidates: ranked candidate predic- tions from a learner. Used to evaluate ranking metrics, rather than just evaluate the single response in the text field.
+ metrics: A teacher can communicate to a learning agent metrics on its performance.
Finally other media can also be supported with additional fields: 
+ image: an image, e.g. for Visual Question Answering or Visual Dialog datasets



## Code Structure
The ParlAI codebase has five main directories: • core: the primary code for the platform. 
+ agents: contains agents which can interact with the worlds/tasks (e.g. learning models).
+ examples: contains examples of different mains (display data, training and evaluation).
+ tasks: contains code for the different tasks available from within ParlAI.
+ mturk: contains code for setting up Mechan- ical Turk and sample MTurk tasks.

### core
+ agent.py:定义所有代理的代理基类，它实现observe（）和act（）方法，Teacher类也报告度量，以及MultiTaskTeacher进行多任务培训。
+ teacher.py:用于使用固定聊天日志进行对话的基本教师类。
+ world.py:定义基本World class, DialogPartnerWorld作用于两个对话者、用于两个以上对话者的MultiA-gentDialogWorld以及可以包装所选环境的两个容器：BatchWorld用于批处理培训，HogwildWorld用于跨多个线程进行培训。
+ dict.py:建筑语言文字规范。
+ 计算精确匹配、F1和排名指标以供评估


### tasks
任务分为五类：

+ 问答（QA）：一种简单的对话形式，每个演讲者只需转一圈。任何智能对话代理都应该能够回答问题，并且可以构建许多种类的问题（以及数据集），从而提供一组非常重要的测试。问题回答特别有用，因为如果数据集用QA对标记，并且问题大多是明确的，那么求值比其他形式的对话更简单。

+ 句子完成（完形填空测试）Sentence Completion (Cloze Tests)：代理必须在对话的下一句话中填写缺失的单词。同样，这是一个特殊的对话框任务，但它的优点是数据集制作成本低，评估简单，这就是为什么社区已经构建了几个这样的数据集。

+ 面向目标的对话Goal-Oriented Dialog：更现实的任务类别是在对话结束时有一个目标要实现。例如，一个顾客和一个旅行社讨论一个航班，一个演讲者推荐另一个要看的电影，等等。

+ 闲聊Chit-Chat：对话任务，其中可能没有明确的目标，但更多的是讨论-例如两个发言者讨论体育、电影或共同兴趣。
+ 视觉对话Visual Dialog：对话通常是建立在世界上的物理对象上的，所以我们也把对话任务包括图像和文本。

在ParlAI中选择任务很容易在命令行上执行，如图4中的数据集显示实用程序所示。如果数据集以前没有使用过，ParlAI将自动下载它。因为所有数据集在ParlAI中都是以相同的方式处理的（使用一个对话框API，参见。5） ，一个模拟代理可以在任何一个代理之间切换培训和测试。重要的是，您可以通过提供一个逗号分隔的列表一次指定多个任务（多任务），例如命令行 `-t babi，squad`，来同时使用这两个数据集，甚至所有的QA数据集（`-t #qa`），或者实际上一次在ParlAI中的每个任务（`-t #all`）。其目的是使构建和评估非常丰富的对话模型变得容易。
每个任务都包含在文件夹中

+ build.py：用于设置任务数据的文件，包括首次请求时下载数据。

+ agent.py：包含存在于任务世界中的教师类、代理。

+ world.py：为需要定义新/复杂环境的任务添加（可选）。要添加新任务，必须实现build.py

下载任何需要的数据，以及agent.py为了训练。
如果数据由固定的日志/对话框脚本组成，比如在许多受监控的数据集中（如SQuAD、Ubuntu等），则需要编写非常简单的代码。对于需要定义交互环境的更复杂的设置，可以实现新的world和/teacher

### Mechanical Turk
ParlAI的一个重要部分是与Mechanical Turk无缝集成，用于数据收集、培训或评估。在ParlAI中，Human Turkers也被视为代理，因此Human-Human、Human bot或multiple Human和bot都可以在标准框架内进行对话，根据需要切换角色，而不会对代理进行代码更改。这是因为Turkers也通过相同的接口接收和发送：使用观察/动作指令的字段。我们在第一个版本中提供了两个示例：
+ （i）qa_collector：一个代理，它与Turkers对话，以收集给定上下文段落的问题-答案对，以构建qa数据集，见图2。

+ （ii）model_evaluator模型评估器：收集Turkers对机器人在给定任务中的性能的评级的代理。

运行newMTurk任务需要实现运行主文件（比如运行.py)并为您希望人类对话的世界和代理定义几个特定于任务的参数。对于数据收集任务，代理应提出问题，并向Turker询问问题的答案，如图2所示。其他参数包括任务描述、突厥者在任务中的角色、描述任务的关键字、点击次数和突厥者的奖励。你可以在沙箱模式下运行，然后启动真正的任务，在那里Turker是付费的。对于在线培训或评估，Turker可以与您的机器学习代理交谈，例如LSTM、内存网络或其他实现的技术。新任务可以签入到存储库中，这样研究人员就可以共享数据收集和数据评估过程，并重现实验。


## 实验说明

为了证明ParlAI在行动中的作用，我们在表1中给出了DrQA的结果，这是一个专注的LSTM架构，在班和bAbI任务上进行了单任务和多任务训练，据我们所知，这是以前没有用任何方法展示过的组合。这个实验同时显示了

ParlAI的力量——建立这个实验是多么容易——以及目前方法的局限性。几乎所有在班上工作得很好的方法都被设计成从给定的上下文中预测一个短语（它们在训练中被指定为开始和结束索引）。因此，这些模型不能应用于所有对话数据集，例如，一些bAbI任务包括是/否问题，其中“是”和“否”不会出现在上下文中。这说明研究人员不应该把模型集中在单个数据集上。ParlAI不提供开始和结束标签索引，因为它的API只是对话框，见图5。这是一个经过深思熟虑的选择，可以阻止这种数据集过度拟合/专门化。然而，这也会导致性能略有下降，因为提供的信息较少5（66.4 EM vs.69.5 EM，见（Chen et al.，2017），这仍然在许多现有的良好表现方法的范围内，见https://stanford-qa.com). 总体而言，DrQA可以解决一些

bAbI在班上任务和表现良好，与bAbI上的最佳表现方法不匹配（Seo et al.，2016；Henaff et al.，2016），多任务也无济于事。因此，ParlAI向社区提出了一个挑战，即寻找普遍适用的学习算法，并从许多对话数据集的培训中获益。

5因为我们现在不知道真正答案的位置，

我们随机选取匹配给定训练集答案的任何上下文短语的开始和结束索引，在某些情况下这是唯一的。


# Response Quality in Human-Chatbot Collaborative Systems 
Jiepu jiang


# 相关综述
https://arxiv.org/pdf/2006.12442.pdf
Facebook AI主管人 Stephen Roller 做这个github https://stephenroller.com/ 虽然不是ParAI的一作，但是还是写了一些综述提到 ParAI和相关研究的





